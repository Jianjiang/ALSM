**********
Chapter 14 -- Logistic Regression, Poisson Regression, and Generalized Linear Models
================================================================================
**********

```{r set-global-opts, include=FALSE}
opts_chunk$set(cache=TRUE, tidy=FALSE)
```

Load the data sets
----------------------------------------------------------------------------

```{r}
env <- new.env()
load("../data.rda", envir = env)
```

Input Programming Task Data
----------------------------------------------------------------------------

```{r}
df <- get("CH14TA01", envir = env)
names(df) <- c("x", "y", "fitted")
```

TABLE 14.1 and FIGURE 14.5    (p 566)
----------------------------------------------------------------------------

#### Data and Maximum Likelihood Estimates--Programming Task Example
#### Scatter Plot, Lowess Curve, and Estimated Logistic Mean Response Function--Programming Task Example

```{r}
fit <- glm(y ~ x, family = binomial(link = "logit"), df)
cbind(
  'Experience'   = df$x,
  'Task Success' = df$y,
  'Fitted Value' = df$fitted,
  'Residual'     = resid(fit))

summary(fit)  # Estimates and Standard Deviations
exp(coef(fit)[2])  # Estimated Odds Ratio
exp(15 * coef(fit)[2])  # Estimated Odds Ratio for 15 Months Training (p 567)

# Plot Logistic Regression and Loess Fit
xx <- with(df, seq(min(x), max(x), len = 200))
plot(y ~ x, df, pch = 19, col = "gray40", xlab = "Experience (X)", ylab = "Fitted Value")
lines(xx, predict(loess(y ~ x, df), data.frame(x = xx)), lty = 2, col = 'blue')
lines(xx, predict(fit, data.frame(x = xx), type = "resp"), lwd = 2)
title("Scatter Plot with Loess (blue) and Logistic Mean Response Functions")
```


FIGURE 14.6     (P 568)
----------------------------------------------------------------------------

#### Logistic, Probit, and Complementary Log-Log Fits--Programming Task Example

Since we can see how the logistic curve looks previously, I made it gray so it would not stand out. Frankly, it is hard to see anyway because the probit curve (blue) lays nearly on top of it.

```{r}
plot(y ~ x, df, pch = 19, col = "gray40", xlab = "Experience (X)", ylab = "Fitted Value")
title("Logistic (Gray), Probit (Blue), and \nComplementary Log-Log (Red) Fitted Models")

fit <- glm(y ~ x, data = df, family = binomial(link = "probit"))
lines(xx, predict(fit, data.frame(x = xx), type = "resp"), col = 'blue', lwd = 2, lty = 2)

fit <- glm(y ~ x, data = df, family = binomial(link = "cloglog"))
lines(xx, predict(fit, data.frame(x = xx), type = "resp"), col = 'red', lwd = 2, lty = 2)

fit <- glm(y ~ x, family = binomial(link = "logit"), df)
lines(xx, predict(fit, data.frame(x = xx), type = "resp"), col = 'gray40', lwd = 2)
```


Input Coupon Effectiveness Data
----------------------------------------------------------------------------

```{r}
df <- get("CH14TA02", envir = env)
names(df) <- c("x", "n", "y", "p")
```


TABLE 14.2 and FIGURE 14.7     (p 569-70)
----------------------------------------------------------------------------

#### Data--Coupon Effectiveness Example
#### Plot of Proportions of Coupons Redeemed and Fitted Logistic Response Function--Coupon Effectiveness Example

```{r}
# Recreate the data from the summary table
fit <- glm(y ~ x, family = binomial(link = 'logit'), data = data.frame(y = c(rep(1, sum(df$y)), rep(0, 1000 - sum(df$y))),
                                                                       x = c(rep(df$x, df$y), rep(df$x, 200 - df$y))))
exp(coef(fit)) 

plot(p ~ x, df, pch = 19, col = "gray40", ylim = c(0, 1), xlim = c(0, 40),
     xlab = "Price Reduction ($)", ylab = "Proportion Redeemed")
lines(seq(0, 40, len = 200), predict(fit, data.frame(x = seq(0, 40, len = 200)), type = "resp"))
title("Proportion of Coupons Redeemed and \nFitted Logistic Response Function")
```

Input Dwaine Studio Data
----------------------------------------------------------------------------

Since we cannot find the Coronary Heart Disease data set, we're going to use the Dwaine Studio data set mentioned at this point in the book. While it has a continuous response variable, we're going to recode it as a binary outcome. 

```{r}
df <- get("CH06FI05", envir = env)
names(df) <- c("x1", "x2", "y")
df <- transform(df, y = ifelse(y < median(y), 0, 1))  # Create dichotomous response
```



FIGURE 14.8
----------------------------------------------------------------------------

#### Three-Dimensional Fitted Logistic Response Surface--Dwaine Studio Example

Here we define a modification to the `lm3d` function used at points throughout these tutorials. In particular, we update the `predict` command to include `type = 'resp'` to get the right sort of prediction intervals from `predict.glm`. 

```{r}
glm3d <- function(model, res, ...) {
  ivs <- labels(terms(model))
  x <- model.frame(model)[, ivs[1]]     # 1st independent variable
  y <- model.frame(model)[, ivs[2]]     # 2nd independent variable  
  xr <- seq(min(x), max(x), len = res)  # equidistant sequence from range of 1st iv
  yr <- seq(min(y), max(y), len = res)  # equidistant sequence from range of 2nd iv
  
  # Create a list object of these sequences to be turned into a grid
  newdata <- list(xr, yr)
  names(newdata) <- ivs
  newdata <- do.call('expand.grid', newdata)
  
  zr <- matrix(predict(model, newdata, type = 'resp'), res, res)
  persp(xr, yr, zr, ...)
}
fit <- glm(y ~ x1 + x2, binomial(link = 'logit'), df)
glm3d(fit, res=45, tick = "detailed", shade = 0.5, expand = 2/3, theta = 300, phi = 30, 
      xlab = "x1", ylab = "x2", zlab = "y")
glm3d(fit, res=45, tick = "detailed", shade = 0.5, expand = 2/3, theta = 330, phi = 0, 
      xlab = "x1", ylab = "x2", zlab = "y")
```


Input Disease Outbreak Data
----------------------------------------------------------------------------

```{r}
df <- get("CH14TA03", envir = env)
names(df) <- c('id', 'x1', 'x2', 'x3', 'x4', 'y')
```


TABLE 14.3 and TABLE 14.4     (p 574)
----------------------------------------------------------------------------

#### Model-Building Data Set--Disease Outbreak Example
#### Maximum Likelihood Estimates of Logistic Regression Function--Disease Outbreak Example

```{r}
fit <- glm(y ~ x1 + x2 + x3 + x4, data = df, family = binomial(link = 'logit'))
cbind(df, 'fitted' = fitted(fit))

cbind(summary(fit)$coefficients, 'OR' = exp(coef(fit)))
vcov(fit)
```


Input IPO Data
----------------------------------------------------------------------------

```{r}
df <- get("APPENC11", envir = env)[2:3]
names(df) <- c('Y', 'X')
df <- transform(df, X = log(X))  # log scale X
df <- transform(df, x = scale(X, T, F), xx = scale(X, T, F)^2)  # Center log X and square it
```



FIGURE 14.9 and TABLE 14.5     (p 575-6)
----------------------------------------------------------------------------

#### First- and Second-Order Logistic Regression Fits with Loess Smooths--IPO Example.
#### Logistic Regression Output for Second-Order Model--IPO Example.

```{r poly-plot, fig.width=12, fig.height=6}
par(mfrow = c(1,2))
xr <- with(df, seq(min(X), max(X), len = 200))  # Plotting range values from log of X

fit <- glm(Y ~ X, binomial(link = 'logit'), df)
plot(Y ~ X, df, pch = 19, col = "gray")
title("(a) First-Order Fit")
lines(xr, predict(loess(Y ~ X, df), data.frame(X = xr)), lty = 2, lwd = 2, col = 'blue')
lines(xr, predict(fit, data.frame(X = xr), type = "resp"), lwd = 2)

fit <- glm(Y ~ x + xx, binomial(link = "logit"), df)
plot(Y ~ X, df, pch = 19, col = "gray")
title("(b) Second-Order Fit")
lines(xr, predict(loess(Y ~ X, df), data.frame(X = xr)), lty = 2, lwd = 2, col = 'blue')
lines(xr, predict(fit, data.frame(x = scale(xr, T, F), xx = scale(xr, T, F)^2), type = "resp"), lwd = 2)

summary(fit)  # TABLE 14.5
```


Input Programming Task Data
----------------------------------------------------------------------------

```{r}
df <- get("CH14TA01", envir = env)
names(df) <- c("x", "y", "fitted")
```

EXAMPLES     (p 578-9)
----------------------------------------------------------------------------

#### Inferences about Regression Parameters--Programming Task Example

```{r}
fit <- glm(y ~ x, data = df, family = binomial)
summary(fit)  # the results are already supplied
```

#### Wald Test

```{r wald-test, eval=FALSE}

cat('z* =', coef(fit)[2] / sqrt(diag(vcov(fit))[2]))
cat('z(0.95) =', qnorm(0.95))
cat('p-value =', 1-pnorm(coef(fit)[2] / sqrt(diag(vcov(fit))[2])))  # Input 'z*'
```
```{r wal-test-show, echo=FALSE}
cat('z* =', coef(fit)[2] / sqrt(diag(vcov(fit))[2]))
cat('z(0.95) =', qnorm(0.95))
cat('p-value =', 1-pnorm(coef(fit)[2] / sqrt(diag(vcov(fit))[2])))  # Input 'z*'
```

#### Interval Estimation

```{r int-est, eval=FALSE}
confint.default(fit)[2, ]                       # this result is based on asymptotic normality
exp(5 * coef(fit)[2])                           # Point estimate for 5 months of training
exp(5 * confint.default(fit)[2, ])              # Confidence limits for 5 months of training
(exp(5 * confint.default(fit)[2, ]) - 1) * 100  # Percentage change form
```
```{r int-est-show, echo=FALSE}
confint.default(fit)[2, ]
exp(5 * coef(fit)[2])
exp(5 * confint.default(fit)[2, ])
(exp(5 * confint.default(fit)[2, ]) - 1) * 100
```

#### Asymptoticaly Normality through Bootstrapping (p 579)

Here we're going to do a quick bootstrapping example to check if bootstrapping on our `n=25` data set is consistent with large sample theory. If so, then using the `confint.default` instead of `confint` above is justified. Otherwise, the interval estimates would have wider limits than generated earlier. 

Note, not every `glm` in the bootstrapping results in convergence, giving rise to warnings that are suppressed in this output.

```{r boot, message=FALSE, warning=FALSE}
library(boot)
boot.beta <- function(data, indices) {coef(glm(y ~ x, binomial, data = data[indices, ]))[2]}
z <- boot(df, boot.beta, R = 1000)
boot.ci(z, type = c("perc", "bca"))
```


Input Disease Outbreak Data
----------------------------------------------------------------------------

```{r}
df <- get("CH14TA03", envir = env)
names(df) <- c('id', 'x1', 'x2', 'x3', 'x4', 'y')
```

